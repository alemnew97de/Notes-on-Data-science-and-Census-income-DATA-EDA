{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNL6GMyLrhRYHZPTRqvZSVX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alemnew97de/Census-income-DATA-EDA/blob/main/logestic_ridge_and_lasso_regressions_with_practicalls.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOeheXay3LTo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine learning algorithm\n",
        "\n",
        "1. Ridge and lasso Regression\n",
        "\n",
        "cost function~~~ gives gradient descent\n",
        "Eg.if no d/ce or error,cost function=0~~~~~~Assume training data\n",
        "\n",
        "Aim reduce Cost function\n",
        "eg. new data given,provides\n",
        "A. Overfitting\n",
        "1.low biase(training data)\n",
        " and high variance(test data)\n",
        "B. under fitting\n",
        "2. High biase and high variance\n",
        "C.generilized model\n",
        "3. low biase and low variance\n",
        "\n",
        "*iteration(how maney times chaning teta to get convergence.\n",
        "\n",
        "Ridge--L2 regularization\n",
        "prevent overfitting\n",
        "\n",
        "Lasso ~~ L1 Regularization\n",
        "\n",
        "lamda-- feature selection and prevent underfitting\n",
        "1. perform feature selection and prevent overfitting\n",
        "\n",
        "Lamda~~ cross Validation"
      ],
      "metadata": {
        "id": "1dozOx8s3RQ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assumption of LR\n",
        "1.Normal or gaussion distribution--Model will get trained wll\n",
        "2. Standardization{ scalling data} ~Z-score, mean=0 and std=1\n",
        "3. works Linearity data\n",
        "4. Multi collinearity{x1,x2,x3~~~y}\n",
        "Drop a feature if similar data and use only x2 to estimate y.\n",
        "****Variation inflation factor\n",
        "\n",
        "Logistic Regression(classification)~~~Binary class\n",
        "\n",
        "use of lg here---1,line greater than zero but value b/n 0 and 1.\n",
        "\n",
        "decision boundary LR\n",
        "- sigmoid activation function to squash a line\n",
        "not use cost function to LR,SINCE it is convex function.\n",
        "since it has a lot of global minima and never reach one one local minima\n",
        "\n",
        "soln; cost function use different formula= OUTPUT--NON CONVEX FUNCTION\n",
        " [Y=0,Y=1]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y4UBKRnOAMFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PERFORMANE MATRICS-CLASSIFICATION PROBLEM\n",
        "\n",
        "X1,X2,~~~Y AND y HAT,given values\n",
        "\n",
        "identify the accuracy\n",
        "using prediction and actuall values~~~~confussion matrix.\n",
        "data given\n",
        "0~900\n",
        "1~100--------inbalance data---affect the algorithm due to biase data, not only dependet accuracy.\n",
        "precision\n",
        "\n",
        "recall----out of all actuall values how many predicted as TP\n",
        "\n",
        "f-score: whenever false positive ad false negative equally important\n"
      ],
      "metadata": {
        "id": "mH7QBIBRUSLS"
      }
    }
  ]
}